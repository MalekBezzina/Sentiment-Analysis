{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aejnu0JaubT5"
      },
      "source": [
        "#Build a logistic regression model to classify movie reviews as either positive or negative.\n",
        "# Task 1 LOAD THE DATASET \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJgsI00zuQib",
        "outputId": "9adf14d7-b0cf-489e-80a4-395c01509129"
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "df=pd.read_csv('/content/data/moviedata.csv', engine='python', encoding='utf-8', error_bad_lines=False )\n",
        "print(df.head(10))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review  sentiment\n",
            "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
            "1  OK... so... I really like Kris Kristofferson a...          0\n",
            "2  ***SPOILER*** Do not read this, if you think a...          0\n",
            "3  hi for all the people who have seen this wonde...          1\n",
            "4  I recently bought the DVD, forgetting just how...          0\n",
            "5  Leave it to Braik to put on a good show. Final...          1\n",
            "6  Nathan Detroit (Frank Sinatra) is the manager ...          1\n",
            "7  To understand \"Crash Course\" in the right cont...          1\n",
            "8  I've been impressed with Chavez's stance again...          1\n",
            "9  This movie is directed by Renny Harlin the fin...          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Skipping line 26458: unexpected end of data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9SzuVN5usWv"
      },
      "source": [
        "# Task 2 transforming documents to feature vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg5uL0KTutql",
        "outputId": "a5bb9bac-6c32-404c-f479-fabddaf00361"
      },
      "source": [
        "import numpy as np \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count=CountVectorizer()\n",
        "docs =np.array(['The sun is shining','The weather is sweet','The sun is shining,The weather is sweet,and one and one is two'])\n",
        "bag=count.fit_transform(docs)\n",
        "\n",
        "print(count.vocabulary_)\n",
        "print(bag.toarray())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 6, 'sun': 4, 'is': 1, 'shining': 3, 'weather': 8, 'sweet': 5, 'and': 0, 'one': 2, 'two': 7}\n",
            "[[0 1 0 1 1 0 1 0 0]\n",
            " [0 1 0 0 0 1 1 0 1]\n",
            " [2 3 2 1 1 1 2 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwqwcWyZuvrH"
      },
      "source": [
        "# Task 3 TF IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGzLDRyXuyf3",
        "outputId": "563af3d6-4722-4206-dd4e-b1ccb839ae48"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf=TfidfTransformer(use_idf=True,norm='l2',smooth_idf=True)\n",
        "print(tfidf.fit_transform(bag).toarray())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.43370786 0.         0.55847784 0.55847784 0.\n",
            "  0.43370786 0.         0.        ]\n",
            " [0.         0.43370786 0.         0.         0.         0.55847784\n",
            "  0.43370786 0.         0.55847784]\n",
            " [0.50238645 0.44507629 0.50238645 0.19103892 0.19103892 0.19103892\n",
            "  0.29671753 0.25119322 0.19103892]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPluW5MEu0g_"
      },
      "source": [
        "# Task 4 Data preparation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HduvSkEEu2pd",
        "outputId": "a79062c7-5c33-46ba-cba8-4e8d8aea51d5"
      },
      "source": [
        "print(df.loc[0,'review'][-50:])\n",
        "\n",
        "import  re\n",
        "def preprocessor(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\\\)|\\\\(|D|P)', text)\n",
        "    text = re.sub('[\\\\W]+', ' ', text.lower()) +\\\n",
        "         ' '.join(emoticons).replace('-', '')\n",
        "    return text\n",
        "\n",
        "print(preprocessor(df.loc[0,'review'][-50:]))\n",
        "\n",
        "print(preprocessor(\"</a>This :) is a :( test :-)!\"))\n",
        "\n",
        "\n",
        "df['review']=df['review'].apply(preprocessor)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is seven.<br /><br />Title (Brazil): Not Available\n",
            "is seven title brazil not available\n",
            "this is a test :) :( :)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfSKgTr2u6nv"
      },
      "source": [
        "#  Task 5 tokenization of documents "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyYawJvXu83G",
        "outputId": "7b977c8e-60e2-4651-a369-026ec73f3d6c"
      },
      "source": [
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "porter = PorterStemmer()\n",
        "\n",
        "def tokenizer(text):\n",
        "    return text.split()\n",
        "def tokenizer_porter(text):\n",
        "    return[porter.stem(word) for word in text.split()]\n",
        "\n",
        "print(tokenizer('runners like running and thus they run'))\n",
        "print(tokenizer_porter('runners like running and thus they run'))\n",
        "\n",
        "\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop =stopwords.words('english')\n",
        "[w for w in tokenizer_porter ('a runner likes running and runs a lot ')[-10:] if w not in stop ]\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['runners', 'like', 'running', 'and', 'thus', 'they', 'run']\n",
            "['runner', 'like', 'run', 'and', 'thu', 'they', 'run']\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runner', 'like', 'run', 'run', 'lot']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3b90DlPu_hH"
      },
      "source": [
        "# Task 6 transform text data into tf idf vectors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufsQZHtfvBtI"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf=TfidfVectorizer(\n",
        "    strip_accents=None,\n",
        "    lowercase=False,\n",
        "    preprocessor=None,\n",
        "    tokenizer=tokenizer_porter,\n",
        "    use_idf=True,\n",
        "    norm='l2',\n",
        "    smooth_idf=True\n",
        "    )\n",
        "\n",
        "y=df.sentiment.values\n",
        "X=tfidf.fit_transform(df.review)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBJFWSr2vD-n"
      },
      "source": [
        "# Task 7 Document classification using logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbDXElYXvHAW",
        "outputId": "16131f5f-5818-47db-8895-e62d577950f5"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,y,random_state=1,test_size=0.5,shuffle=False)\n",
        "\n",
        "import pickle\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "\n",
        "clf=LogisticRegressionCV(cv=5,scoring='accuracy',random_state=0,n_jobs=-1,verbose=3,max_iter=300).fit(x_train,y_train)\n",
        "saved_model=open('saved_model.sav','wb')  \n",
        "pickle.dump(clf,saved_model)\n",
        "saved_model.close()        \n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.5min finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLv2kZGKvJWA"
      },
      "source": [
        "# Task 8 Model Evaluation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfP7SdqvvLwi",
        "outputId": "08100288-953d-4af7-ee16-ad1077738dc9"
      },
      "source": [
        "filename='saved_model.sav'\n",
        "saved_clf=pickle.load(open(filename,'rb'))\n",
        "\n",
        "saved_clf.score(x_test,y_test)\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8858482007862111"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}